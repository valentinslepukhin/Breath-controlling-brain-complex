{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2158,
     "status": "ok",
     "timestamp": 1588362755395,
     "user": {
      "displayName": "Valentin Slepukhin",
      "photoUrl": "",
      "userId": "03748456046691696053"
     },
     "user_tz": 420
    },
    "id": "t6jkBFMArg3x",
    "outputId": "03188630-8707-435f-a721-2133eebe51f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1\n",
    "import numpy as np\n",
    "%pylab \n",
    "#style.use('ggplot')\n",
    "#rcParams['figure.figsize'] = 12,8\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import copy\n",
    "import networkx as nx\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import connectivity as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (1.0.5)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (1.3.4)\n",
      "Requirement already satisfied: plotly in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (5.7.0)\n",
      "Requirement already satisfied: matplotlib in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (3.4.3)\n",
      "Requirement already satisfied: six in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (0.19.2)\n",
      "Requirement already satisfied: scipy in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from catboost) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/valentinslepukhin/opt/anaconda3/lib/python3.9/site-packages (from plotly->catboost) (8.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8pOugDVrg35"
   },
   "source": [
    "Matrix connectivity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0KNVzhErg36"
   },
   "outputs": [],
   "source": [
    "#Erdos-Renyi connectivity matrix \n",
    "@jit(nopython = True)\n",
    "def getRandomConnectivity(N, pct_connected):\n",
    "    #Directed mapping\n",
    "    M = np.random.rand(N**2).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (i == j):\n",
    "                M[i,j] = 0\n",
    "            else:\n",
    "                if (M[i,j] < pct_connected):\n",
    "                    M[i,j] = 1 #i connects to j\n",
    "                else:\n",
    "                    M[i,j] = 0\n",
    "    return M\n",
    "\n",
    "@jit(nopython = True)\n",
    "def kill_reciprocal(N,M):\n",
    "  for i in range(N):\n",
    "    for j in range(i):\n",
    "      if ((M[i,j] == 1) and (M[j,i] == 1)):\n",
    "        q =np.random.randint(2)\n",
    "        if (q==0):\n",
    "          M[i,j] = 0\n",
    "        else:\n",
    "          M[j,i] = 0\n",
    "  return(M)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Addition of motives by completing the triangle\n",
    "@jit(nopython=True)\n",
    "def addmotives(N,M,l,nummotives):\n",
    "    for m in range(nummotives):\n",
    "        c = 0\n",
    "        while (c == 0):\n",
    "            a = 0\n",
    "            while(a < 2):\n",
    "                i = np.random.randint(N)\n",
    "                a = int(l[i,0])\n",
    "            j1 = 0\n",
    "            j2 = 0\n",
    "            while (j1 == j2):\n",
    "                j1 = np.random.randint(a)+1\n",
    "                j2 = np.random.randint(a)+1\n",
    "            b = int(l[j1,0])\n",
    "            d = 0\n",
    "            for k in range(b):\n",
    "                if (j2 == int(l[j1,k+1])):\n",
    "                    d = 1\n",
    "            if (d==0):\n",
    "                l[j1,0] = l[j1,0] + 1\n",
    "                l[j1,b + 1] = j2\n",
    "                c=1\n",
    "    return(l)\n",
    "        \n",
    "\n",
    "\n",
    "#Addition of motives by adding full triangle    \n",
    "def addmotives2(N,M,nummotives):\n",
    "    m = 0\n",
    "    while(m<nummotives):\n",
    "        i = np.random.randint(N)\n",
    "        j = np.random.randint(N)\n",
    "        k = np.random.randint(N)\n",
    "        if (M[i,j]==0):\n",
    "            M[i,j] = 1\n",
    "            m = m + 1\n",
    "        if (M[j,k]==0):\n",
    "            M[j,k] = M[j,k] + 1\n",
    "            m = m + 1\n",
    "        if (M[k,i] == 0):\n",
    "            M[k,i] = M[k,i]+1\n",
    "            m = m + 1\n",
    "    #l = matrixOfEdges(M,N)\n",
    "    return(M)        \n",
    "\n",
    "def numberofmotives(N,M,l):\n",
    "    num = 0\n",
    "    for i in range(N):\n",
    "        a = int(l[i,0])\n",
    "        for j in range(a):\n",
    "            for k in range(a):\n",
    "                l1 = int(l[i,j+1])\n",
    "                l2 = int(l[i,k+1])\n",
    "                if (M[l1,l2]==1):\n",
    "                    num = num + 1\n",
    "    return(num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def findandkillmotives(N,M,l,numtokill):\n",
    "    num = 0\n",
    "    i = 0\n",
    "    while ((i<N)and(num < numtokill)):\n",
    "        a = int(l[i,0])\n",
    "        for j in range(a):\n",
    "            for k in range(a):\n",
    "                l1 = int(l[i,j+1])\n",
    "                l2 = int(l[i,k+1])\n",
    "                if (M[l1,l2]==1):\n",
    "                    num = num + 1\n",
    "                    M[l1,l2] = 0\n",
    "        i = i + 1\n",
    "    return(M,num)\n",
    "    \n",
    "def getrandomvector(N,ics):\n",
    "    V=zeros(N)\n",
    "    p=ics*1.0/N\n",
    "    for i in range(N):\n",
    "        if (np.random.rand(1)<p):\n",
    "            V[i]=1\n",
    "    return(V)\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def matrixOfEdges(M,N):\n",
    "    N = int(N)\n",
    "    E=np.zeros(N**2).reshape(N,N)  #prepare array with zeros\n",
    "    k=np.sum(M,0) #array with degree of each vertex\n",
    "    for i in range(N):\n",
    "        a=int(k[i]) #degree of the current vertex\n",
    "        E[i,0]=a  #we put it to the zero row of matrix of edges\n",
    "    for i in range(N):\n",
    "        a=int(k[i])\n",
    "        q=1\n",
    "        for j in range(N):\n",
    "            if (M[j,i]==1):\n",
    "                E[i,q]=j #all the next elements in current column are number of vertices current vertex is connected to\n",
    "                q=q+1\n",
    "    return(E)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def recovermatrixfromlist(E,N):\n",
    "    q=0;\n",
    "    M=np.zeros(N*N).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        a=E[i,0]\n",
    "        b=int(a)\n",
    "        for j in range(b):\n",
    "            k=E[i,j+1]\n",
    "            l=int(k)\n",
    "            M[i,l]=1\n",
    "    return(M)\n",
    "\n",
    "\n",
    "def doubleconstellation(N,k):\n",
    "    M=np.zeros(N*N).reshape(N,N)\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            M[i,j+k]=1            \n",
    "    for i in range(N-2*k):\n",
    "        for j in range(k):\n",
    "            M[i+2*k,j]=1\n",
    "            M[j+k,i+2*k]=1\n",
    "    return(M)\n",
    "\n",
    "\n",
    "\n",
    "def constellationwithrandom(N,k,p):\n",
    "    Edges=(2*(N-2*k)*k-k*k)*1.0\n",
    "    M=np.zeros(N*N).reshape(N,N)\n",
    "    for i in range(k):\n",
    "        for j in range(k):\n",
    "            M[i,j+k]=1            \n",
    "    for i in range(N-2*k):\n",
    "        for j in range(k):\n",
    "            M[i+2*k,j]=1\n",
    "            M[j+k,i+2*k]=1\n",
    "    p=p-Edges*1.0/(N*N-N)\n",
    "    Q = np.random.rand(N**2).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (i == j):\n",
    "                M[i,j] = 0\n",
    "            else:\n",
    "                if (Q[i,j] < p):\n",
    "                    M[i,j] = 1 #i connects to j\n",
    "    return(M)\n",
    "\n",
    "\n",
    "def constantdegree(N,k):\n",
    "    M=zeros(N*N).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(k):\n",
    "            m=np.random.randint(N)\n",
    "            M[i,m]=1\n",
    "    return(M)\n",
    "\n",
    "\n",
    "def coordinates(A,m,d):\n",
    "    X=A\n",
    "    coords=np.zeros(d)\n",
    "    remainder=np.zeros(d)\n",
    "    for i in range(d):\n",
    "        (X,coords[i])=divmod(X,m)\n",
    "    return(coords)\n",
    "\n",
    "def distance(A,B,m,d):\n",
    "    coordsa = coordinates(A,m,d)\n",
    "    #print(coordsa)\n",
    "    coordsb = coordinates(B,m,d)\n",
    "    #print(coordsb)\n",
    "    vecdist=np.zeros(d)\n",
    "    for i in range(d):\n",
    "        vecdist[i]=(coordsa[i]-coordsb[i])**2\n",
    "    dist=np.sum(vecdist)\n",
    "    return(dist)\n",
    "\n",
    "def localmatr(m,d,p,a):\n",
    "    N=m**d\n",
    "    M = np.random.rand(N**2).reshape(N,N)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if (i == j):\n",
    "                M[i,j] = 0\n",
    "            else:\n",
    "                if (M[i,j] < p*np.exp(-a*distance(i,j,m,d))):\n",
    "                    #print(distance(i,j,m,d))\n",
    "                    M[i,j] = 1 #i connects to j\n",
    "                else:\n",
    "                    M[i,j] = 0\n",
    "    return M\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def ranvec(N,n):\n",
    "    vec=np.zeros(N)\n",
    "    for i in range(n):\n",
    "        a=np.random.randint(N)\n",
    "        while(vec[a]==1):\n",
    "            a=np.random.randint(N)\n",
    "        vec[a]=1\n",
    "    return(vec)\n",
    "\n",
    "def random_initial_state(N,n_times,n):\n",
    "    states = np.zeros(N*n_times).reshape(N,n_times) - 1\n",
    "    vec = ranvec(N,n)\n",
    "    for i in range(N):\n",
    "        states[i,0] = -1  - vec[i]\n",
    "    return(states)\n",
    "\n",
    "def add_one_active(N,vec):\n",
    "    i = np.random.randint(N)\n",
    "    while(vec[i] == 1):\n",
    "        i = np.random.randint(N)\n",
    "    vec[i] = 1\n",
    "    return(vec)\n",
    "\n",
    "def vector_to_matrix(N,n_times,vec):\n",
    "    states = np.zeros(N*n_times).reshape(N,n_times) - 1\n",
    "    for i in range(N):\n",
    "        states[i,0] = -1 - vec[i]\n",
    "    return(states)\n",
    "\n",
    "\n",
    "def spike_raster_plot(N, n_timesteps, stepsize, states):\n",
    "    neuralData = []\n",
    "    for i in range(N):\n",
    "        neuralData.append([])\n",
    "        for j in range(n_timesteps):\n",
    "            if (states[i,j] == 0):\n",
    "                neuralData[i].append(j*stepsize)\n",
    "    return(neuralData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qWyB0Z3jrg4B"
   },
   "source": [
    "Dynamic functions, the simplest approach: background noise just contributes to the potential. We assume it to contribute equally to all neurons, we do not take here into account variations in the noise, we assume all the neurons to be identical.The growth of the EPSP is instanateous in this model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CfoPpPpyrg4C"
   },
   "outputs": [],
   "source": [
    "#Here we are trying another approach by taking into account synaptic delay.\n",
    "\n",
    "#The function that updates neuron's state based on its current state and input.\n",
    "\n",
    "#We are not modeling laser activated neurons as separate entities \n",
    "#but just as the same neuronsvwith additional input\n",
    "@jit(nopython=True)\n",
    "def neuron_state_update(state, inp, voltage, refr, threshold, EPSP_decay, tau_m):\n",
    "    V = voltage * EPSP_decay + inp / tau_m\n",
    "    if ((state < refr) or (V < threshold)):\n",
    "        return(state + 1, V)\n",
    "    else: \n",
    "        return(0,0)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def neuron_state_update_noise(state, inp, voltage, refr, threshold, EPSP_decay, tau_m, noise_freq):\n",
    "    V = voltage * EPSP_decay + inp / tau_m\n",
    "    to_fire = np.random.rand()\n",
    "    if (((state < refr) or (V < threshold)) and (to_fire > noise_freq) ):\n",
    "        return(state + 1, V)\n",
    "    else: \n",
    "        return(0,0)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def neuron_state_update_2(state, inp, voltage, refr, threshold, EPSP_decay, tau_m):\n",
    "    V = voltage * EPSP_decay + inp / tau_m\n",
    "    if ((state < refr) or (V < threshold)):\n",
    "        return(state + 1, V,0)\n",
    "    else: \n",
    "        return(0,0,0)\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def neuron_state_update_noise_2(state, inp, voltage, refr, threshold, EPSP_decay, tau_m, noise_freq):\n",
    "    V = voltage * EPSP_decay + inp / tau_m\n",
    "    to_fire = np.random.rand()\n",
    "    if (((state < refr) or (V < threshold)) and (to_fire > noise_freq) ):\n",
    "        return(state + 1, V,0)\n",
    "    elif (to_fire <= threshold): \n",
    "        return(0,0,1)\n",
    "    \n",
    "@jit(nopython=True)    \n",
    "def neuron_output(state,n_neighbors, W_synapse, tau_s, mu,  sigma):\n",
    "    for i in range(n_neighbors):\n",
    "        if (state == 0):\n",
    "            W_synapse[i] = np.random.lognormal(mu, sigma)\n",
    "            print(W_synapse[i])\n",
    "    return(W_synapse*state*np.exp(-state / tau_s), W_synapse)\n",
    "    \n",
    "    \n",
    "\n",
    "#It is not real excitation, but effective one\n",
    "@jit(nopython=True) \n",
    "def excitation_by_laser(V, mu, sigma, n_spikes, n_timesteps):\n",
    "    output = np.zeros(n_timesteps)\n",
    "    j = 0\n",
    "    for i in range(n_spikes):\n",
    "        per = int(np.random.lognormal(mu, sigma))\n",
    "        j = j + per\n",
    "        output[j] = V\n",
    "    return(output)\n",
    "\n",
    "\n",
    "@jit(nopython=True) \n",
    "def excitation_by_laser_2(V, period, deviation, stepsize, n_spikes, n_timesteps):\n",
    "    output = np.zeros(n_timesteps)\n",
    "    j = int(np.random.normal(20 / stepsize, 3 / stepsize))\n",
    "    output[j] = V\n",
    "    for i in range(n_spikes - 1):\n",
    "        per = int(np.random.normal(period / stepsize, deviation / stepsize))\n",
    "        j = j + per\n",
    "        output[j] = V\n",
    "    return(output)\n",
    "\n",
    "@jit(nopython = True)\n",
    "def one_step_LIF(state, input_matrix, voltage,syn_del, W_syn,  edges, t, parameters):\n",
    "    EPSP_decay = parameters[0] # we multiply voltage to this constant every step to get exponential decay\n",
    "    refr = int(parameters[1]) \n",
    "    mu = parameters[2] \n",
    "    sigma = parameters[3]\n",
    "    tau_s = int(parameters[4])\n",
    "    tau_m = int(parameters[5])\n",
    "    threshold = parameters[7] #threshold for the transition\n",
    "    n_neurons = int(parameters[8]) #total number of neurons\n",
    "    \n",
    "    for i in range(n_neurons):\n",
    "        statei = state[i,t]\n",
    "        n_neighbors = int(edges[i,0])\n",
    "        W_synapse = np.zeros(n_neighbors)\n",
    "        out = np.zeros(n_neighbors)\n",
    "        constant = statei*np.exp(-statei / tau_s)\n",
    "        for j in range(n_neighbors):\n",
    "            out[j] = W_syn[i,j]*constant\n",
    "        #out, W_synapse = neuron_output(statei,n_neighbors, W_synapse, tau_s, mu,  sigma)\n",
    "            neighbor = int(edges[i, j+1])\n",
    "            delay = int(syn_del[i,j])\n",
    "            input_matrix[neighbor, t + delay + 1] = input_matrix[neighbor, t + delay + 1] + out[j]\n",
    "    for i in range(n_neurons):\n",
    "        state[i, t + 1], voltage[i, t + 1] = neuron_state_update(state[i, t ], input_matrix[i, t], voltage[i, t ], refr, threshold, EPSP_decay,tau_m)\n",
    "        \n",
    "    return(state, input_matrix, voltage)\n",
    "\n",
    "@jit(nopython = True)\n",
    "def create_noise_vector(N, fraction):\n",
    "  nv = np.zeros(N)\n",
    "  for i in range(N):\n",
    "    p = np.random.rand()\n",
    "    if (p < fraction):\n",
    "      nv[i] = 1\n",
    "  return(nv)\n",
    "\n",
    "@jit(nopython = True)\n",
    "def one_step_LIF_noise(state, input_matrix, voltage,syn_del, W_syn,  edges, t, parameters, noise_freq, noise_vector, activated_by_noise):\n",
    "    EPSP_decay = parameters[0] # we multiply voltage to this constant every step to get exponential decay\n",
    "    refr = int(parameters[1]) \n",
    "    mu = parameters[2] \n",
    "    sigma = parameters[3]\n",
    "    tau_s = int(parameters[4])\n",
    "    tau_m = int(parameters[5])\n",
    "    threshold = parameters[7] #threshold for the transition\n",
    "    n_neurons = int(parameters[8]) #total number of neurons\n",
    "  \n",
    "    \n",
    "    for i in range(n_neurons):\n",
    "        statei = state[i,t]\n",
    "        n_neighbors = int(edges[i,0])\n",
    "        W_synapse = np.zeros(n_neighbors)\n",
    "        out = np.zeros(n_neighbors)\n",
    "        constant = statei*np.exp(-statei / tau_s)\n",
    "        for j in range(n_neighbors):\n",
    "            out[j] = W_syn[i,j]*constant\n",
    "        #out, W_synapse = neuron_output(statei,n_neighbors, W_synapse, tau_s, mu,  sigma)\n",
    "            neighbor = int(edges[i, j+1])\n",
    "            delay = int(syn_del[i,j])\n",
    "            input_matrix[neighbor, t + delay + 1] = input_matrix[neighbor, t + delay + 1] + out[j]\n",
    "    for i in range(n_neurons):\n",
    "      if (noise_vector[i] == 1):\n",
    "        state[i, t + 1], voltage[i, t + 1], activated_by_noise[i, t+1] = neuron_state_update_noise_2(state[i, t ], input_matrix[i, t], voltage[i, t ], refr, threshold, EPSP_decay, tau_m, noise_freq)\n",
    "      else:\n",
    "        state[i, t + 1], voltage[i, t + 1], activated_by_noise[i, t+1] = neuron_state_update_2(state[i, t ], input_matrix[i, t], voltage[i, t ], refr, threshold, EPSP_decay, tau_m)\n",
    "  \n",
    "\n",
    "    return(state, input_matrix, voltage, activated_by_noise)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def prepare_syndel(average, std, stepsize, edges, n_neurons ):\n",
    "    mu, sigma = prepare_lognormal(average, std, stepsize)\n",
    "    synaptic_del = np.zeros(n_neurons**2).reshape(n_neurons, n_neurons)\n",
    "    for i in range(n_neurons):\n",
    "        for j in range(n_neurons - 1):\n",
    "            if (edges[i, j + 1] > 0):\n",
    "                 syndel = np.random.lognormal(mu, sigma)\n",
    "    return(synaptic_del)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def prepare_syndel_2(average, std, stepsize, edges, n_neurons ):\n",
    "    synaptic_del = np.zeros(n_neurons**2).reshape(n_neurons, n_neurons)\n",
    "    for i in range(n_neurons):\n",
    "      neigh = int(edges[i,0])\n",
    "      for j in range(neigh):\n",
    "        synaptic_del[i,j] = np.random.uniform(average - std, average + std)\n",
    "    return(synaptic_del)\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def prepare_input(V, period, std, stepsize, n_neurons, n_timesteps, n_spikes, set_activated):\n",
    "    input_matrix = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    n_activated = len(set_activated)\n",
    "    mu, sigma = prepare_lognormal(period, std, stepsize)\n",
    "    for i in range(n_activated):\n",
    "        vec = excitation_by_laser(V, mu, sigma, n_spikes, n_timesteps)\n",
    "        number = int(set_activated[i])\n",
    "        for j in range(n_timesteps):\n",
    "            input_matrix[number, j] = vec[j]\n",
    "    return(input_matrix)\n",
    "        \n",
    "    \n",
    "@jit(nopython = True)\n",
    "def prepare_input2(V, period, std, stepsize, n_neurons, n_timesteps, n_spikes, set_activated):\n",
    "    input_matrix = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    n_activated = len(set_activated)\n",
    "    for i in range(n_activated):\n",
    "        vec = excitation_by_laser_2(V, period, std, stepsize, n_spikes, n_timesteps)\n",
    "        number = int(set_activated[i])\n",
    "        for j in range(n_timesteps):\n",
    "            input_matrix[number, j] = vec[j]\n",
    "    return(input_matrix)\n",
    "        \n",
    "@jit(nopython = True)\n",
    "def compact_input(input_matrix, set_activated, n_timesteps, n_spikes):\n",
    "    \n",
    "    n_activated = len(set_activated)\n",
    "    \n",
    "    inp = np.zeros(n_activated * n_spikes).reshape(n_activated, n_spikes)\n",
    "    for i in range(n_activated):\n",
    "        number = int(set_activated[i])\n",
    "        num_of_spike = 0\n",
    "        for j in range(n_timesteps):\n",
    "            \n",
    "            #print(type(num_of_spike))\n",
    "            if (input_matrix[number, j] > 0):\n",
    "                k = int(num_of_spike)\n",
    "                inp[i, k] = j\n",
    "                num_of_spike =num_of_spike + 1\n",
    "             #   print(type(num_of_spike))\n",
    "    #print(inp)\n",
    "    \n",
    "    return(inp)\n",
    "        \n",
    "    \n",
    "\n",
    "                \n",
    "#The full process of synchronization, starting with particular set of activated neurons           \n",
    "@jit(nopython=True)\n",
    "def full_process( edges, syn_del, input_matrix, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector):\n",
    "    n_neurons = int(parameters[8])\n",
    "    stepsize = parameters[9]\n",
    "    \n",
    "    tau_s = int(parameters[4])\n",
    "    activated_by_noise = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    states = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    for i in range(n_neurons):\n",
    "        for j in range(n_timesteps):\n",
    "            states[i,j] = 1000 * tau_s\n",
    "    \n",
    "                \n",
    "    #        print(W_matrix[i,j])\n",
    "    #excitation_by_laser(V, period, std, n_spikes, n_timesteps)\n",
    "    max_del = np.max(syn_del.reshape(n_neurons**2))\n",
    "    V_threshold = parameters[7] \n",
    "    voltages = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    t = 0\n",
    "    av_V = 0\n",
    "    while ((t < n_timesteps - 1 - max_del) and (av_V < V_threshold)):\n",
    "        states, input_matrix, voltages, activated_by_noise = one_step_LIF_noise(states, input_matrix, voltages, syn_del, W_matrix,  edges, t, parameters, noise_freq, noise_vector, activated_by_noise)\n",
    "        t = t + 1\n",
    "        sum_V = 0\n",
    "        for i in range(n_neurons):\n",
    "            sum_V = sum_V + voltages[i,t]\n",
    "        av_V = sum_V / n_neurons    \n",
    "        #print(av_V)\n",
    "    return(states, voltages, activated_by_noise, t)    \n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def full_process_data( edges, syn_del,  W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated):\n",
    "    n_neurons = int(parameters[8])\n",
    "    stepsize = parameters[9]\n",
    "    \n",
    "    tau_s = int(parameters[4])\n",
    "    activated_by_noise = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    states = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    for i in range(n_neurons):\n",
    "        for j in range(n_timesteps):\n",
    "            states[i,j] = 1000 * tau_s\n",
    "    \n",
    "    \n",
    "    set_activated = active_set(N, n_activated) #activated neurons are chosen\n",
    "                \n",
    "    #        print(W_matrix[i,j])\n",
    "    #excitation_by_laser(V, period, std, n_spikes, n_timesteps)\n",
    "    max_del = np.max(syn_del.reshape(n_neurons**2))\n",
    "    V_threshold = parameters[7] \n",
    "    voltages = np.zeros(n_neurons*n_timesteps).reshape(n_neurons, n_timesteps)\n",
    "    t = 0\n",
    "    av_V = 0\n",
    "    input_matrix = prepare_input2(V_laser, period, stdlaser, stepsize, n_neurons, n_timesteps, n_spikes, set_activated)\n",
    "    inp = compact_input(input_matrix, set_activated, n_timesteps, n_spikes)\n",
    "    while ((t < n_timesteps - 1 - max_del) and (av_V < V_threshold)):\n",
    "        states, input_matrix, voltages, activated_by_noise = one_step_LIF_noise(states, input_matrix, voltages, syn_del, W_matrix,  edges, t, parameters, noise_freq, noise_vector, activated_by_noise)\n",
    "        t = t + 1\n",
    "        sum_V = 0\n",
    "        for i in range(n_neurons):\n",
    "            sum_V = sum_V + voltages[i,t]\n",
    "        av_V = sum_V / n_neurons    \n",
    "        #print(av_V)\n",
    "    if (t < n_timesteps - 1 - max_del):\n",
    "        burst = 1\n",
    "    else:\n",
    "        burst = 0\n",
    "    \n",
    "    return(inp, burst)  \n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "@jit(nopython=True)           \n",
    "def prepare_lognormal(av, std,stepsize):   \n",
    "    sigmasq = np.log((std/av)**2 + 1) \n",
    "    sigma = np.sqrt(sigmasq)\n",
    "    mu = np.log(av / stepsize)  - sigmasq / 2.0\n",
    "    return(mu,sigma)    \n",
    "    \n",
    "\n",
    "@jit(nopython=True)                \n",
    "def turn_data_into_scatter(N, n_tim, state):\n",
    "    x = []\n",
    "    y = []\n",
    "    for j in range(n_tim):\n",
    "        for i in range(N):\n",
    "            if (state[i,j] == 0):\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "    return(x,y)\n",
    "    \n",
    "                \n",
    "def probs_times(res, n_timesteps, n_trials, n_curves, n_max, stepsize):\n",
    "    times = []\n",
    "    probs = []\n",
    "    for c in range(n_curves):\n",
    "        t = res[c]\n",
    "        times.append([])\n",
    "        probs.append([])\n",
    "        n_act = []\n",
    "        for i in range(n_max):\n",
    "            n_burst = 0\n",
    "            sum_t = 0\n",
    "            for j in range(n_trials):\n",
    "                if (t[i,j] < n_timesteps - 1):\n",
    "                    n_burst = n_burst + 1\n",
    "                    sum_t = sum_t + t[i,j]                \n",
    "            probs[c].append(n_burst * 1.0 / n_trials)\n",
    "            if (n_burst > 0):\n",
    "                sum_t = sum_t / n_burst\n",
    "                times[c].append(sum_t * stepsize)\n",
    "    return(times, probs)                     \n",
    "            \n",
    "def plotter(times, probs, n_curves, n_max):\n",
    "    n_act = []\n",
    "    n_shifted = np.zeros(n_max)\n",
    "    for i in range (n_max):\n",
    "        n_shifted[i] = i + 1\n",
    "    for i in range(n_curves):\n",
    "        \n",
    "        q = len(times[i])\n",
    "        n_act_vec = np.zeros(q)\n",
    "        for j in range(q):\n",
    "            n_act_vec[j] = n_max - q + j + 1\n",
    "        n_act.append(n_act_vec)\n",
    "    figure(1)\n",
    "    for i in range(n_curves):\n",
    "        plot(n_shifted, probs[i])\n",
    "    figure(2)\n",
    "    for i in range(n_curves):\n",
    "        plot(n_act[i],times[i])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def list_from_matrices(N, edges, syn, W):\n",
    "  e_l = []\n",
    "  s_l = []\n",
    "  W_l = []\n",
    "  for i in range(N):\n",
    "    neigh = int(edges[i,0])\n",
    "    e_l.append([])\n",
    "    s_l.append([])\n",
    "    W_l.append([])\n",
    "    for j in range(neigh):\n",
    "      e_l[i].append(edges[i,j+1])\n",
    "      s_l[i].append(syn[i,j])\n",
    "      W_l[i].append(W[i,j])\n",
    "  return(e_l,s_l,W_l)\n",
    "\n",
    "\n",
    "def weight_matrix(n_neurons, edges, mu,sigma): \n",
    "   W_matrix = np.zeros(n_neurons**2).reshape(n_neurons, n_neurons)\n",
    "   for i in range(n_neurons):\n",
    "     neigh = int(edges[i,0])\n",
    "     for j in range(neigh):\n",
    "      W_matrix[i,j] = np.random.lognormal(mu, sigma)\n",
    "   return(W_matrix)\n",
    "\n",
    "@jit(nopython = True)\n",
    "def active_set(N, n_activated):\n",
    "  set_activated = np.zeros(n_activated)\n",
    "  for i in range(n_activated):\n",
    "    a = np.random.randint(N)\n",
    "    for j in range(i):\n",
    "      while (a == set_activated[j]):\n",
    "        a = np.random.randint(N)\n",
    "    set_activated[i] = a\n",
    "  return(set_activated)    \n",
    "\n",
    "\n",
    "def catboost_data_full_model(data_size, edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated):\n",
    "   \n",
    "    my_dict = {}\n",
    "    inp, burst = full_process_data( edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated)\n",
    "    for k in range(len(inp)):\n",
    "        my_dict[k] = []\n",
    "    my_dict[\"Answer\"] = []\n",
    "    \n",
    "    #print(my_dict)\n",
    "    #X = np.zeros(data_size * num_par).reshape(data_size, num_par) #for not rescaling\n",
    "    #X = []\n",
    "    #Y = []\n",
    "    #perm_size = math.factorial(N)\n",
    "    #pl1 = list(np.arange(N))\n",
    "    #pl_all = list(permutations(pl1)) \n",
    "    for i in range(data_size):\n",
    "        \n",
    "        inp, burst = full_process_data( edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated)\n",
    "\n",
    "        \n",
    "        for k in range(len(inp)):\n",
    "            my_dict[k].append(inp[k]) \n",
    "\n",
    "        my_dict[\"Answer\"].append(burst)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    return(my_dict)  \n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def single_EPSP_magnitude(EPSP_decay, tau_s ,n_steps):\n",
    "    V = np.zeros(n_steps)\n",
    "    for i in range(1,n_steps):\n",
    "        V[i] = V[i - 1] * EPSP_decay + i * exp(-i*1.0/tau_s) / tau_m \n",
    "    return(np.max(V))    \n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def multiple_EPSP_magnitude(delV, tau_m, deltaT):\n",
    "    return(delV/ ( 1 - np.exp(- deltaT / tau_m )))\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def minimal_interval(inp, n_spikes, n_activated):\n",
    "    deriv = np.zeros(n_activated * (n_spikes - 1)).reshape(n_activated, n_spikes - 1)\n",
    "    for i in range(n_activated):\n",
    "        for j in range(n_spikes - 1):\n",
    "            deriv[i,j] = inp[i, j + 1] - inp[i,j]\n",
    "    A = deriv.reshape(n_activated * (n_spikes - 1))\n",
    "    return(np.min(A))\n",
    "\n",
    "\n",
    "        \n",
    "@jit(nopython=True)\n",
    "def lists_to_matrices(N, edges, W, syn_del):\n",
    "    \n",
    "    W_mat = np.zeros(N*N).reshape(N,N)\n",
    "    syn_mat = np.zeros(N*N).reshape(N,N)\n",
    "\n",
    "    for i in range(N):\n",
    "        n_neighbors = int(edges[i,0])\n",
    "        for j in range(n_neighbors):\n",
    "            q = int(edges[i, j + 1])\n",
    "            W_mat[i,q] = W[i, j]\n",
    "            syn_mat[i,q] = syn_del[i,j]\n",
    "    return(W_mat,syn_mat)    \n",
    "        \n",
    "        \n",
    "@jit(nopython=True)\n",
    "def lists_to_matrices_2(N, edges, W, syn_del):\n",
    "    \n",
    "    W_mat = np.zeros(N*N).reshape(N,N)\n",
    "    syn_mat = np.zeros(N*N).reshape(N,N)\n",
    "\n",
    "    for i in range(N):\n",
    "        n_neighbors = int(edges[i,0])\n",
    "        for j in range(n_neighbors):\n",
    "            q = int(edges[i, j + 1])\n",
    "            W_mat[q,i] = W[i, j]\n",
    "            syn_mat[q,i] = syn_del[i,j]\n",
    "    return(W_mat,syn_mat)    \n",
    "            \n",
    "    \n",
    "\n",
    "@jit(nopython = True)\n",
    "def maybe_active(M, edges, syn_del, inp, set_activated, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, n_spikes):\n",
    "    N = int(parameters[8])\n",
    "    n_activated = len(set_activated)\n",
    "    V_threshold = parameters[7]\n",
    "    EPSP_decay = parameters[0]  \n",
    "\n",
    "    tau_s = parameters[4] \n",
    "    tau_m = parameters[5]\n",
    "    stepsize = parameters[9]\n",
    "    n_steps = int(5.0 / stepsize)\n",
    "    delV = single_EPSP_magnitude(EPSP_decay, tau_s , n_steps)\n",
    "    #print(delV)\n",
    "    \n",
    "    deltaT = minimal_interval(inp, n_spikes, n_activated)\n",
    "    #print(deltaT)\n",
    "    max_possible_inp = np.zeros(N)\n",
    "    num_inp = np.zeros(N)\n",
    "    for i in range(n_activated):\n",
    "        n_i = int(set_activated[i])\n",
    "        n_neigh = edges[n_i, 0]\n",
    "        for j in range(n_neigh):\n",
    "            k = int(edges[n_i, j+1])\n",
    "            max_possible_inp[k] += W_matrix[n_i,j] * multiple_EPSP_magnitude(delV, tau_m, deltaT)\n",
    "            num_inp[k] += 1\n",
    "    num_potentially_active = 0\n",
    "    #print(max_possible_inp)\n",
    "    for i in range(N):\n",
    "        if (max_possible_inp[i] > V_threshold):\n",
    "            num_potentially_active += 1\n",
    "    potentially_active = np.zeros(num_potentially_active)\n",
    "    num_inp_above = np.zeros(num_potentially_active)\n",
    "    inp_values = np.zeros(num_potentially_active)\n",
    "    index = 0\n",
    "    for i in range(N):\n",
    "         if (max_possible_inp[i] > V_threshold):\n",
    "                potentially_active[index] = i\n",
    "                num_inp_above[index] = num_inp[i]\n",
    "                inp_values[index] = max_possible_inp[i]\n",
    "                index += 1\n",
    "    return(potentially_active, num_inp_above, inp_values)\n",
    "        \n",
    "                \n",
    "\n",
    "@jit(nopython = True)\n",
    "def small_matrices(pot_act, Matr_itself, set_activated, edges, W_mat, syn_mat):\n",
    "    n_active = len(set_activated)\n",
    "    n_pot = len(pot_act)\n",
    "    M_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    Edge_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    W_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    W_mat_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    syn_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    syn_mat_small = np.zeros(n_pot * n_active).reshape(n_pot, n_active)\n",
    "    for i in range(n_activated):\n",
    "        for j in range(n_pot):\n",
    "            a = int(set_activated[i])\n",
    "            b = int(pot_act[j])\n",
    "            if (Matr_itself[b,a] == 1):\n",
    "                M_small[j,i] = 1\n",
    "                W_mat_small[j,i] = W_mat[a,b]\n",
    "                syn_mat_small[j,i] = syn_mat[a,b]\n",
    "    deg=np.sum(M_small,1) #array with degree of each vertex\n",
    "    deg2 = np.sum(M_small,0)\n",
    "    #print(deg)\n",
    "    #print(deg2)\n",
    "    for i in range(n_pot):\n",
    "        a=int(deg[i]) #degree of the current vertex\n",
    "        Edge_small[i,0]=a  #we put it to the zero row of matrix of edges\n",
    "    for i in range(n_pot):\n",
    "        #a=int(deg[i])\n",
    "        q=1\n",
    "        for j in range(n_active):\n",
    "            if (M_small[i,j]==1):\n",
    "                Edge_small[i,q]=j #all the next elements in current column are number of vertices current vertex is connected to\n",
    "                W_small[i,q-1] = W_mat_small[i,j]\n",
    "                syn_small[i,q-1] = syn_mat_small[i,j]\n",
    "                q=q+1\n",
    "    \n",
    "    return(M_small, Edge_small, W_small, syn_small)\n",
    "                \n",
    "\n",
    "def list_sort_together(list1, list2):\n",
    "    list1, list2 = (list(t) for t in zip(*sorted(zip(list1, list2))))\n",
    "    return(list1, list2)\n",
    "    \n",
    "#@jit(nopython = True)\n",
    "def really_active(M_small, Edge_small, W_small, syn_small, inp,  parameters, n_spikes, n_activated, n_pot):\n",
    "    Spikes_list = [] #= np.zeros(n_pot * n_activated * n_spikes).reshape(n_pot, n_activated * n_spikes)\n",
    "    V_threshold = parameters[7]\n",
    "    EPSP_decay = parameters[0]  \n",
    "    stepsize = parameters[9]\n",
    "    tau_s = parameters[4] \n",
    "    tau_m = parameters[5]\n",
    "    n_steps = int(5.0 / stepsize)\n",
    "    delV = single_EPSP_magnitude(EPSP_decay, tau_s ,n_steps)\n",
    "    for i in range(n_pot):\n",
    "        inp_volts = []\n",
    "        volts = [0]\n",
    "        \n",
    "        times = [0]\n",
    "        \n",
    "        index = []\n",
    "        spikes = []\n",
    "        k = int(Edge_small[i,0])\n",
    "        for j in range(n_spikes):\n",
    "            Inp_volts = []\n",
    "            Times = []\n",
    "            for q in range(k):\n",
    "                out_neur = int(Edge_small[i, q + 1])\n",
    "                out_time = inp[out_neur, j]\n",
    "                Times.append(out_time + syn_small[i, q ]) \n",
    "                #print(\"inp-append\", W_small[i, q ])\n",
    "                Inp_volts.append(W_small[i, q ] * delV)\n",
    "                index.append(j)\n",
    "                volts.append(0)\n",
    "            Times, Inp_volts = list_sort_together(Times, Inp_volts)\n",
    "            inp_volts += Inp_volts\n",
    "            times += Times\n",
    "        #print(inp_volts)\n",
    "        #print(times)\n",
    "        for j in range(1, len(times)):\n",
    "         #   print(\"Inp = \", inp_volts[j - 1])\n",
    "            volts[j] = volts[j-1] * np.exp(-(times[j] - times[j-1]) / tau_m) + inp_volts[j - 1]\n",
    "            if (volts[j] > V_threshold):\n",
    "                spikes.append(index[j - 1])\n",
    "                volts[j] = 0\n",
    "          #  print(\"Volts = \",volts[j])\n",
    "        #print(volts)\n",
    "        #print(spikes)\n",
    "                \n",
    "        Spikes_list += spikes\n",
    "        \n",
    "    counter = np.zeros(n_spikes)\n",
    "    for i in range(len(Spikes_list)):\n",
    "        counter[Spikes_list[i]] += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return(counter)\n",
    "\n",
    "\n",
    "def temporal_data_same(data_size,edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated):\n",
    "    my_dict = {}\n",
    "    #for k in range(n_spikes):\n",
    "    #    my_dict[k] = []\n",
    "    my_dict[\"Input\"] = []\n",
    "    my_dict[\"Answer\"] = []\n",
    "    for i in range(data_size):\n",
    "        delV = single_EPSP_magnitude(EPSP_decay, tau_s , 1000)\n",
    "        input_matrix = prepare_input2(V_laser, period, stdlaser, stepsize, n_neurons, n_timesteps, n_spikes, set_activated)\n",
    "    #print(3)\n",
    "        inp = compact_input(input_matrix, set_activated, n_timesteps, n_spikes)\n",
    "        W_mat, syn_mat = lists_to_matrices(N, edges, W_matrix, syn_del)\n",
    "    #inp, b = full_process_data( edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated)\n",
    "        A,B,C, t = full_process( edges, syn_del, input_matrix, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector)\n",
    "        if (t < n_timesteps - np.max(syn_del) - 1):\n",
    "            b = 1\n",
    "        else:\n",
    "            b = 0\n",
    "        pot_act, num_inp, inp_values = maybe_active(M, edges, syn_del, inp, set_activated, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, n_spikes)\n",
    "        \n",
    "        M_small, Edge_small, W_small, syn_small = small_matrices(pot_act, M, set_activated, edges, W_mat, syn_mat)\n",
    "   \n",
    "        n_activated = len(set_activated)\n",
    "        n_pot = len(pot_act)\n",
    "        res = really_active(M_small, Edge_small, W_small, syn_small, inp,  parameters, n_spikes, n_activated, n_pot)\n",
    "        mres = np.max(res)\n",
    "        #for k in range(n_spikes):\n",
    "         #   my_dict[k].append(res[k])\n",
    "            #my_dict[k].append(np.random.rand())\n",
    "        my_dict[\"Input\"].append(mres)    \n",
    "        my_dict[\"Answer\"].append(b)\n",
    "        \n",
    "    return(my_dict)\n",
    "           \n",
    "          \n",
    "def temporal_data_dif_mat_dif_jit(data_size,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated):\n",
    "    my_dict = {}\n",
    "    #for k in range(n_spikes):\n",
    "    #    my_dict[k] = []\n",
    "    my_dict[\"Weights\"] = []\n",
    "    #my_dict[\"Edges\"] = []\n",
    "    my_dict[\"std\"] = []\n",
    "    \n",
    "    my_dict[\"Set activated\"] = []\n",
    "    \n",
    "    my_dict[\"Answer\"] = []\n",
    "    \n",
    "    my_dict[\"Times spiking\"] = []\n",
    "    for i in range(data_size):\n",
    "        if (i%10 == 0):\n",
    "            print(i)\n",
    "        N = 1000 #total number of neurons\n",
    "\n",
    "        n_neurons = N #the same thing\n",
    "        parameters[8] = N\n",
    "\n",
    "        p = 0.065 #probability of the directed connection\n",
    "\n",
    "\n",
    "        M = getRandomConnectivity(N,p) #prepare connectivity matrix of the network. In this case ER matrix.\n",
    "        edges = matrixOfEdges(M,N)  #other form of this matrix\n",
    "        W_matrix = weight_matrix(n_neurons, edges, mu,sigma) #matrix of synaptic weights\n",
    "\n",
    "\n",
    "        set_activated = active_set(N, n_activated)\n",
    "        syn_del = prepare_syndel_2(avdel, stddel, stepsize, edges, n_neurons ) #matrix of synaptic delays\n",
    "        #stdlaser = period * np.random.rand() / 3.0    \n",
    "        delV = single_EPSP_magnitude(EPSP_decay, tau_s , 1000)\n",
    "        input_matrix = prepare_input2(V_laser, period, stdlaser, stepsize, n_neurons, n_timesteps, n_spikes, set_activated)\n",
    "    #print(3)\n",
    "        inp = compact_input(input_matrix, set_activated, n_timesteps, n_spikes)\n",
    "        W_mat, syn_mat = lists_to_matrices_2(N, edges, W_matrix, syn_del)\n",
    "    #inp, b = full_process_data( edges, syn_del, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated)\n",
    "        A,B,C, t = full_process( edges, syn_del, input_matrix, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector)\n",
    "        if (t < n_timesteps - np.max(syn_del) - 1):\n",
    "            b = 1\n",
    "        else:\n",
    "            b = 0\n",
    "        pot_act, num_inp, inp_values = maybe_active(M, edges, syn_del, inp, set_activated, W_matrix,  parameters, n_timesteps, noise_freq, noise_vector, n_spikes)\n",
    "        \n",
    "        M_small, Edge_small, W_small, syn_small = small_matrices(pot_act, M, set_activated, edges, W_mat, syn_mat)\n",
    "   \n",
    "        n_activated = len(set_activated)\n",
    "        n_pot = len(pot_act)\n",
    "        #res = really_active(M_small, Edge_small, W_small, syn_small, inp,  parameters, n_spikes, n_activated, n_pot)\n",
    "        #mres = np.max(res)\n",
    "        #for k in range(n_spikes):\n",
    "         #   my_dict[k].append(res[k])\n",
    "            #my_dict[k].append(np.random.rand())\n",
    "        #my_dict[\"Input\"].append(mres) \n",
    "        my_dict[\"Weights\"].append(W_mat)\n",
    "        \n",
    "        my_dict[\"std\"].append(stdlaser)\n",
    "    \n",
    "        my_dict[\"Set activated\"].append(set_activated)\n",
    "    \n",
    "        \n",
    "    \n",
    "        my_dict[\"Times spiking\"].append(inp)\n",
    "        \n",
    "        my_dict[\"Answer\"].append(b)\n",
    "        \n",
    "    return(my_dict)\n",
    "           \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "@jit(nopython = True)\n",
    "def order_n_vec(X,n,N):\n",
    "    T = np.zeros(N)\n",
    "    for i in range(N):\n",
    "            T[i] = X[i]**n\n",
    "    return(T)\n",
    "            \n",
    "def data_change(my_dict, N,n):\n",
    "    my_dict[n] = []\n",
    "    \n",
    "    lW = my_dict[\"Weights\"]\n",
    "    lX = my_dict[\"Set activated\"] \n",
    "    for i in range(len(lW)):\n",
    "        X = np.zeros(N)\n",
    "        n_act = len(lX[i])\n",
    "        for j in range(n_act):\n",
    "            a = int(lX[i][j])\n",
    "            X[a] = 1\n",
    "        X_new = np.matmul(lW[i], X)\n",
    "        my_dict[n].append(np.sum(order_n_vec(X_new, n, N)))\n",
    "    return(my_dict)\n",
    "\n",
    "def data_change_2(my_dict, N,n):\n",
    "    my_dict[n] = []\n",
    "    \n",
    "    lW = my_dict[\"Weights\"]\n",
    "    lX = my_dict[\"Set activated\"] \n",
    "    for i in range(len(lW)):\n",
    "        X = np.zeros(N)\n",
    "        n_act = len(lX[i])\n",
    "        for j in range(n_act):\n",
    "            a = int(lX[i][j])\n",
    "            X[a] = 1\n",
    "        for j in range(n):\n",
    "            X = np.matmul(lW[i], X)\n",
    "        my_dict[n].append(np.sum(order_n_vec(X, 2, N)))\n",
    "    return(my_dict)\n",
    "\n",
    "\n",
    "\n",
    "def data_change_Alex(my_dict, N,n):\n",
    "    for i in range(n):\n",
    "        my_dict[i] = []\n",
    "    \n",
    "    lW = my_dict[\"Weights\"]\n",
    "    lX = my_dict[\"Set activated\"] \n",
    "    for i in range(len(lW)):\n",
    "        X = np.zeros(N*N).reshape(N,N)\n",
    "        n_act = len(lX[i])\n",
    "        for j in range(n_act):\n",
    "            a = int(lX[i][j])\n",
    "            X[a,a] = 1\n",
    "        for j in range(n):\n",
    "            my_dict[j].append(np.sum(X))\n",
    "            X = np.matmul(lW[i], X)\n",
    "    print(len(my_dict[\"Weights\"]))\n",
    "    for i in range(n):\n",
    "        print(len(my_dict[i]))\n",
    "    return(my_dict)\n",
    "\n",
    "def data_change_Alex_inverse(my_dict, N,alpha):\n",
    "    my_dict[alpha] = []\n",
    "    \n",
    "    \n",
    "    lW = my_dict[\"Weights\"]\n",
    "    lX = my_dict[\"Set activated\"] \n",
    "    for i in range(len(lW)):\n",
    "        X = np.zeros(N*N).reshape(N,N)\n",
    "        n_act = len(lX[i])\n",
    "        for j in range(n_act):\n",
    "            a = int(lX[i][j])\n",
    "            X[a,a] = 1\n",
    "        A =  np.matmul(lW[i], X)\n",
    "        B = np.identity(N) - alpha * A \n",
    "        C = np.matmul(A, inv(B))\n",
    "        my_dict[alpha].append(np.sum(C))\n",
    "    \n",
    "    return(my_dict)\n",
    "\n",
    "\n",
    "\n",
    "def transform_data(my_dict, N,n):\n",
    "    my_dict[n + 2000] = []\n",
    "    l = len(my_dict[0])\n",
    "    for i in range(l):\n",
    "        X = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            X[j] = my_dict[j][i]\n",
    "        my_dict[n + 2000].append(np.sum(order_n_vec(X, n, N)))\n",
    "    return(my_dict)\n",
    "\n",
    "\n",
    "def all_possible_parameters(my_dict, N):\n",
    "    first_powers = 4\n",
    "    second_powers = 3\n",
    "    idm = np.identity(N)\n",
    "    for i in range(first_powers * 2 * second_powers):\n",
    "        my_dict[i ] = []\n",
    "    lW = my_dict[\"Weights\"]\n",
    "    lX = my_dict[\"Set activated\"] \n",
    "    for i in range(len(lW)):\n",
    "        X = np.zeros(N)\n",
    "        n_act = len(lX[i])\n",
    "        for j in range(n_act):\n",
    "            a = int(lX[i][j])\n",
    "            X[a] = 1\n",
    "        V1 = np.matmul(lW[i],X)\n",
    "        for s1 in range(first_powers):\n",
    "            V2 = order_n_vec(V1, s1, N)\n",
    "            for s2 in range(2):\n",
    "                if (s2==0):\n",
    "                    V3 = np.matmul(idm, V2)\n",
    "                else:\n",
    "                    V3 = np.matmul(lW[i], V2)\n",
    "                for s3 in range(second_powers):\n",
    "                    V4 = order_n_vec(V3, s3, N)\n",
    "                    numb = s3 + s2*second_powers + s1 * 2 * second_powers\n",
    "                    my_dict[numb] = np.sum(V4)\n",
    "    return(my_dict)\n",
    "                    \n",
    "            \n",
    "                    \n",
    "                    \n",
    "        \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-_gYUIqdnl5"
   },
   "source": [
    "# Parameters of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-0yXkRqdwRU"
   },
   "outputs": [],
   "source": [
    "stepsize = 0.05 #the size of the time step, in milliseconds\n",
    "n_timesteps = 10000 #the total number of steps (if burst is reached simulation stops immediately after the burst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "099jlPg_a7Nu"
   },
   "source": [
    "# Parameters of the individual neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1nkpXQtbKd2"
   },
   "outputs": [],
   "source": [
    "refr = 3 / stepsize # refractory period of the neuron. Number before division is in milliseconds \n",
    "tau_s = 0.5 / stepsize #tau_s from the equation for the current I = W * t * exp(-t/ tau_s). Number in ms.\n",
    "tau_m = 25 / stepsize #tau_m membrane time constant in milliseconds\n",
    "V_threshold = 12.4 #the threshold voltage in millivolts\n",
    "EPSP_decay = np.exp(-1.0 / tau_m )  # the factor by which the voltage decays following the equations\n",
    "V_EPSP = 2.8 #average magnitude of EPSP in mV\n",
    "std_EPSP = 1.5 #standard deviation of EPSP in mV\n",
    "W_average = 300 #approximate value of the parameter W in the equation for current (see above) in mV\n",
    "sigmasq = np.log((std_EPSP/V_EPSP)**2 + 1) #square of parameter sigma in lognormal distribution \n",
    "sigma = np.sqrt(sigmasq) #parameter sigma in lognormal distribution\n",
    "mu = np.log(W_average) - sigmasq / 2.0  #parameter mu in lognormal distribution\n",
    "mu = mu + np.log(stepsize) #changing the stepsize goes into mu in this way\n",
    "noise_freq = 0.0005 * stepsize # frequency over the noise in kHz (1/ms)\n",
    "avdel = 1.3 / stepsize  #average synaptic delay time. In ms before division\n",
    "stddel = 1.1 / stepsize #standard deviation of the synaptic delay time. In ms before division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hd91PLhN3CIq"
   },
   "source": [
    "# Creating the Erdos-Renyi network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yoV2jsx_3GxP"
   },
   "outputs": [],
   "source": [
    "N = 1000 #total number of neurons\n",
    "\n",
    "n_neurons = N #the same thing\n",
    "\n",
    "p = 0.065 #probability of the directed connection\n",
    "\n",
    "\n",
    "M = getRandomConnectivity(N,p) #prepare connectivity matrix of the network. In this case ER matrix.\n",
    "edges = matrixOfEdges(M,N)  #other form of this matrix\n",
    "W_matrix = weight_matrix(n_neurons, edges, mu,sigma) #matrix of synaptic weights\n",
    "\n",
    "\n",
    "    \n",
    "syn_del = prepare_syndel_2(avdel, stddel, stepsize, edges, n_neurons ) #matrix of synaptic delays\n",
    "\n",
    "e_l, s_l , W_l = list_from_matrices(N, edges, syn_del, W_matrix) #write all the matrices in a form convenient for output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7yTuYnNxtFe"
   },
   "source": [
    "#Creating localized network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S0TiYePuhhT9"
   },
   "source": [
    "# Parameters of the laser activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3MkRHsvis4L"
   },
   "outputs": [],
   "source": [
    " #laser activation is modeled as very strong  input to the neuron during one step requrring few times to make the neuron fire multiple times. \n",
    "N = 1000\n",
    "V_laser = 20 * tau_m #magnitude of the input. Should be enough to make neuron to fire \n",
    "period = 39.2 #average period of spiking after laser stimulation in ms, taken from frequency in Kaiwen paper\n",
    "stdlaser = 4.7 #standard deviation  of the period\n",
    "n_spikes = 7 #number of spikes\n",
    "n_activated = 7 #number of activated neurons\n",
    "set_activated = active_set(N, n_activated) #activated neurons are chosen\n",
    "#set activated is a list of numbers. You also can give it explicitly, for example \n",
    "#set_activated = [1,2,3,4,5,6,7] \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1EfB_BLOlZsJ"
   },
   "source": [
    "# Prepare the list with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZP99Es-lw42"
   },
   "outputs": [],
   "source": [
    "N = 1000\n",
    "parameters = np.zeros(10)\n",
    "parameters[0] = EPSP_decay \n",
    "parameters[1] = refr\n",
    "parameters[2] = mu \n",
    "parameters[3] = sigma \n",
    "parameters[4] = tau_s \n",
    "parameters[5] = tau_m\n",
    "parameters[7] = V_threshold \n",
    "parameters[8] = n_neurons\n",
    "parameters[9] = stepsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KCDL1oR_UXA"
   },
   "source": [
    "#Specifying which neurons can produce noise and which can not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XSLQBF20_Spv"
   },
   "outputs": [],
   "source": [
    "noise_fraction = 0.0 #fraction of noicy neurons\n",
    "\n",
    "noise_vector = create_noise_vector(N, noise_fraction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Customary libraries\n",
    "import connectivities as cn #Different network connectivities\n",
    "import physiological_neurons as ph #Dynamics of leaky integrate ad fire neurons\n",
    "import parameters as pr #Parameters of the simulation \n",
    "\n",
    "def data_with_saving(data_size, first_powers, second_powers):\n",
    "    \n",
    "    par = pr.my_params()\n",
    "    N = int(par['n_neurons']) #total number of neurons\n",
    "    n_activated = int(par['Number of laser activated neurons'])\n",
    "    n_timesteps = int(par['n_timesteps'])\n",
    "    noise_fraction = 0.0 #fraction of noicy neurons\n",
    "\n",
    "    noise_vector = ph.create_noise_vector(N, noise_fraction)\n",
    "\n",
    "    my_dict = {}\n",
    "    my_dict[\"Answer\"] = []\n",
    "    \n",
    "    \n",
    "    idm = np.identity(N)\n",
    "    for i in range(first_powers * 2 * second_powers):\n",
    "        my_dict[i] = []\n",
    "        \n",
    "    for i in range(data_size):\n",
    "        \n",
    "        M, edges, W_matrix, syn_del = cn.generate_network(par)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        set_activated = cn.active_set(N, n_activated) #activated neurons are chosen\n",
    "    \n",
    "        input_matrix = ph.prepare_input2(par, set_activated)\n",
    "        \n",
    "        X = np.zeros(N)\n",
    "        \n",
    "        if (i%10 == 0):\n",
    "            print(i)\n",
    "       \n",
    "\n",
    "        \n",
    "        W_mat, syn_mat = cn.lists_to_matrices_2(N, edges, W_matrix, syn_del)\n",
    "        A,B, t = ph.full_process( edges, syn_del, input_matrix, W_matrix,  par, noise_vector)\n",
    "        if (t < n_timesteps - np.max(syn_del) - 1):\n",
    "            b = 1\n",
    "        else:\n",
    "            b = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(n_activated):\n",
    "            a = int(set_activated[j])\n",
    "            X[a] = 1\n",
    "        V1 = np.matmul(W_mat,X)\n",
    "        for s1 in range(first_powers):\n",
    "            V2 = order_n_vec(V1, s1 + 1, N)\n",
    "            for s2 in range(2):\n",
    "                if (s2==0):\n",
    "                    V3 = np.matmul(idm, V2)\n",
    "                else:\n",
    "                    V3 = np.matmul(W_mat, V2)\n",
    "                for s3 in range(second_powers):\n",
    "                    V4 = order_n_vec(V3, s3 + 1, N)\n",
    "                    numb = s3 + s2*second_powers + s1 * 2 * second_powers\n",
    "                    totres = np.sum(V4)\n",
    "                    my_dict[numb] = [totres]\n",
    "        \n",
    "        \n",
    "        \n",
    "        my_dict[\"Answer\"] = b\n",
    "        df = pd.DataFrame(my_dict)\n",
    "        df.to_csv('data4.csv', mode='a')\n",
    "        \n",
    "    return(my_dict)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "10\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "20\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "30\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "40\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "50\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "60\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "70\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "80\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "90\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "Data obtained\n"
     ]
    }
   ],
   "source": [
    "data_size = 100\n",
    "first_powers = 4\n",
    "second_powers = 3\n",
    "data_multiple_matrix_N_1000_r_4 = data_with_saving(data_size, parameters, n_timesteps, noise_freq, noise_vector, V_laser, period, stdlaser, n_spikes, n_activated)  \n",
    "print(\"Data obtained\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def multiple_splitting(X, y, n_split, split_fraction):\n",
    "    ac_score = np.zeros(n_split)\n",
    "    simple_score = np.zeros(n_split)\n",
    "    categorical_features_indices = np.where(X.dtypes != np.float)[0]\n",
    "    for i in range(n_split):\n",
    "        X_train, X_validation, y_train, y_validation = train_test_split(X, y, train_size= split_fraction)\n",
    "        train_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\n",
    "        validate_pool = Pool(X_validation, y_validation, cat_features=categorical_features_indices)\n",
    "        num_iter = 1000\n",
    "        alpha = 0.2\n",
    "        \n",
    "        params = {\n",
    "            'iterations': 500,\n",
    "            'learning_rate': 0.1,\n",
    "            'eval_metric': 'Accuracy',\n",
    "    #'random_seed': 42,\n",
    "            'logging_level': 'Silent',\n",
    "            'use_best_model': False\n",
    "        }\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=validate_pool)\n",
    "\n",
    "        best_model_params = params.copy()\n",
    "        best_model_params.update({\n",
    "            'use_best_model': True\n",
    "        })\n",
    "     \n",
    "\n",
    "        ac_score[i] = accuracy_score(y_validation, model.predict(X_validation))\n",
    "        \n",
    "    return(ac_score)\n",
    "\n",
    "\n",
    "def prepare_input(df4, cols):\n",
    "    X = df4\n",
    "    all_col = df4.columns\n",
    "    for c in all_col:\n",
    "        if (c in cols)==False:\n",
    "            X = X.drop(c, axis=1)\n",
    "            \n",
    "    return X       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/n0m6fkj96kg58ft5bw7k66ym0000gw/T/ipykernel_23939/4280563854.py:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  categorical_features_indices = np.where(X.dtypes != np.float)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.76271186, 0.71186441, 0.77966102, 0.69491525, 0.69491525])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('data4.csv')\n",
    "\n",
    "X = prepare_input(df4, ['0'])\n",
    "\n",
    "y = df4.Answer\n",
    "n_split = 5\n",
    "split_fraction = 0.75\n",
    "\n",
    "multiple_splitting(X, y, n_split, split_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "LIF-neurons-distinguished.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
